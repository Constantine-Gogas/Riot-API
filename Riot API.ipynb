{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37706928",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caedf549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25500820",
   "metadata": {},
   "source": [
    "# API Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aac7b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API key (expires after 24 hours)\n",
    "api_key = \"RGAPI-51c2aa98-8c71-42ee-bb0b-5397eb8e786d\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2878bd1",
   "metadata": {},
   "source": [
    "# Summoner Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bd7eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Summoner Names and Tags \n",
    "summoner_name_list = [\"KRP%20Kirai/KRP\", \"KRP%20SummerChild/SUCH\", \"KRP%20Nightreign/KRP\"]\n",
    "#summoner_name_list = [\"KRP%20SummerChild/SUCH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27af78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summoner_name_url = \"https://europe.api.riotgames.com/riot/account/v1/accounts/by-riot-id/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7a8fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summoner_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd2b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each summoner name and fetch data\n",
    "for summoner_name in summoner_name_list:\n",
    "    full_summoner_name_url = summoner_name_url + summoner_name + \"?api_key=\" + api_key\n",
    "    \n",
    "    # Send request\n",
    "    resp = requests.get(full_summoner_name_url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if resp.status_code == 200:\n",
    "        player_info = resp.json()\n",
    "        summoner_data.append(player_info)  # Append the JSON response to the list\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {summoner_name}: {resp.status_code}\")\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "summoner_df = pd.DataFrame(summoner_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(summoner_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb8e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "summoner_df.to_excel(\"summoner_df.xlsx\", index=False)\n",
    "\n",
    "print(\"Excel file saved: summoner_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5b3d0f",
   "metadata": {},
   "source": [
    "# Summoner Matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d271a1ca",
   "metadata": {},
   "source": [
    "### Unix Dates (Start-End Dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f4da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define start and end dates\n",
    "start_date = datetime(2021, 6, 16)\n",
    "end_date = datetime.today()\n",
    "\n",
    "# Generate date ranges\n",
    "date_ranges = []\n",
    "while start_date < end_date:\n",
    "    week_end = start_date + timedelta(days=6)  # 7-day range\n",
    "    week_end = week_end.replace(hour=23, minute=59, second=59)  # Ensure full day is covered\n",
    "    \n",
    "    unix_start = int(time.mktime(start_date.timetuple()))\n",
    "    unix_end = int(time.mktime(week_end.timetuple()))  # Now includes full 7 days\n",
    "\n",
    "    date_ranges.append([start_date.strftime('%Y-%m-%d'), week_end.strftime('%Y-%m-%d'), unix_start, unix_end])\n",
    "    \n",
    "    start_date += timedelta(days=7)  # Move to the next week\n",
    "\n",
    "\n",
    "unix_dates_df = pd.DataFrame(date_ranges, columns=['Start Date', 'End Date', 'Unix Start', 'Unix End'])\n",
    "\n",
    "\n",
    "print(unix_dates_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35487aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_str = start_date.strftime(\"%Y_%m_%d\")\n",
    "end_str = end_date.strftime(\"%Y_%m_%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1748e990",
   "metadata": {},
   "source": [
    "## Data Source\n",
    "\n",
    "We are using an Excel file that contains a list of summoner name-tags along with their corresponding Match IDs.  \n",
    "For each summoner, the dataset includes their **first 100 matches** retrieved from the Riot API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6510366",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a list to store all match data\n",
    "match_data_list = []\n",
    "\n",
    "# Loop through each summoner\n",
    "for index_summoner, summoner_row in summoner_df.iterrows():\n",
    "    match_puuid = summoner_row['puuid']\n",
    "    \n",
    "    # Loop through each unix date range\n",
    "    for index_date, date_row in unix_dates_df.iterrows():\n",
    "        match_startTime = str(date_row['Unix Start'])\n",
    "        match_endTime = str(date_row['Unix End'])\n",
    "        \n",
    "        match_url = (\n",
    "            \"https://europe.api.riotgames.com/lol/match/v5/matches/by-puuid/\" +\n",
    "            match_puuid +\n",
    "            \"/ids?startTime=\" + match_startTime +\n",
    "            \"&endTime=\" + match_endTime +\n",
    "            \"&start=0&count=100\" +\n",
    "            \"&api_key=\" + api_key\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            match_resp = requests.get(match_url)\n",
    "            match_resp.raise_for_status()  # Raise error for bad responses\n",
    "            matches = match_resp.json()  # This is the list of match IDs\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching matches for {summoner_row['gameName']} between {match_startTime} and {match_endTime}: {e}\")\n",
    "            matches = None\n",
    "        \n",
    "        # If matches found, add them to the list\n",
    "        if matches:\n",
    "            for match in matches:\n",
    "                match_data_list.append({\n",
    "                    \"gameName\": summoner_row['gameName'],\n",
    "                    \"tagLine\": summoner_row['tagLine'],\n",
    "                    \"puuid\": match_puuid,\n",
    "                    \"match_url\": match_url,\n",
    "                    \"match_id\": match,  # Store individual match ID\n",
    "                    \"startTime\": match_startTime,\n",
    "                    \"endTime\": match_endTime,\n",
    "                    \n",
    "                })\n",
    "\n",
    "# Convert to DataFrame\n",
    "match_data_list = pd.DataFrame(match_data_list)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(match_data_list)\n",
    "\n",
    "file_path = (\n",
    "    r\"match_data_list_\" +\n",
    "    str(unix_dates_df['Unix Start'].min()) + \"_\" +\n",
    "    str(unix_dates_df['Unix End'].max()) + \".xlsx\"\n",
    ")\n",
    "match_data_list.to_excel(file_path, index=False)\n",
    "\n",
    "print(\"Excel file named match_data_list.xlsx saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f7c729",
   "metadata": {},
   "source": [
    "### URLs for Match IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e6c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_match_id_list = []\n",
    "matchID_url_base = \"https://europe.api.riotgames.com/lol/match/v5/matches/\" \n",
    "\n",
    "for match_id in match_data_list['match_id']:\n",
    "     matchID_url =  matchID_url_base + match_id + \"?api_key=\" + api_key\n",
    "     \n",
    "     test_match_id_list.append({\n",
    "                    \"match_id\": match_id,\n",
    "                    \"matchID_url\": matchID_url    \n",
    "                })\n",
    "       \n",
    "    \n",
    "#print(test_match_id_list)\n",
    "# Convert the list to a DataFrame\n",
    "test_match_id_list_df = pd.DataFrame(test_match_id_list)\n",
    "\n",
    "file_path = (\n",
    "    r\"test_match_id_list_\" +\n",
    "    str(unix_dates_df['Unix Start'].min()) + \"_\" +\n",
    "    str(unix_dates_df['Unix End'].max()) + \".xlsx\"\n",
    ")\n",
    "test_match_id_list_df.to_excel(file_path, index=False)\n",
    "\n",
    "\n",
    "print(\"Excel file named test_match_id_list saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd44d76b",
   "metadata": {},
   "source": [
    "### Riot Match Participants Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c7a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of URLs from the DataFrame column\n",
    "riot_links = test_match_id_list_df[\"matchID_url\"].tolist()\n",
    "\n",
    "# Store player-level data\n",
    "all_players_data = []\n",
    "\n",
    "for url in riot_links:\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        match_id = data['metadata']['matchId']\n",
    "        game_duration = data['info']['gameDuration']\n",
    "        game_mode = data['info']['gameMode']\n",
    "        participants_info = data['info']['participants']\n",
    "        participants_puuids = data['metadata']['participants']\n",
    "\n",
    "        # Optional check to skip malformed matches\n",
    "        if len(participants_info) != len(participants_puuids):\n",
    "            print(f\"Skipping match {match_id} due to participant length mismatch\")\n",
    "            continue\n",
    "\n",
    "        for i, player in enumerate(participants_info):\n",
    "            puuid = participants_puuids[i]  # safely assigned\n",
    "            player_data = {\n",
    "                \"Match ID\": match_id,\n",
    "                \"Game Mode\": game_mode,\n",
    "                \"Game Duration\": game_duration,\n",
    "                \"PUUID\": puuid,\n",
    "                \"Summoner Name\": player.get(\"summonerName\"),\n",
    "                \"Champion Name\": player.get(\"championName\"),\n",
    "                \"Team Position\": player.get(\"teamPosition\"),\n",
    "                \"Lane\": player.get(\"lane\"),\n",
    "                \"Kills\": player.get(\"kills\"),\n",
    "                \"Deaths\": player.get(\"deaths\"),\n",
    "                \"Assists\": player.get(\"assists\"),\n",
    "                \"Win\": player.get(\"win\"),\n",
    "                \"Total Damage To Champs\": player.get(\"totalDamageDealtToChampions\"),\n",
    "                \"Total Damage Taken\": player.get(\"totalDamageTaken\"),\n",
    "                \"Gold Earned\": player.get(\"goldEarned\"),\n",
    "                \"Total Minions Killed\": player.get(\"totalMinionsKilled\"),\n",
    "                \"Vision Score\": player.get(\"visionScore\"),\n",
    "            }\n",
    "\n",
    "            all_players_data.append(player_data)\n",
    "        time.sleep(2.0)  # Respect Riot API rate limits\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\" Error fetching {url}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_players_data)\n",
    "\n",
    "# Save to Excel with dynamic filename\n",
    "file_path = (\n",
    "    r\"riot_match_participants_\" +\n",
    "    str(unix_dates_df['Unix Start'].min()) + \"_\" +\n",
    "    str(unix_dates_df['Unix End'].max()) + \".xlsx\"\n",
    ")\n",
    "df.to_excel(file_path, index=False)\n",
    "\n",
    "print(\"Participants data successfully saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c11444",
   "metadata": {},
   "source": [
    "### Data Source for Champion Matchup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe by Match ID and PUUID to ensure consistent player ordering\n",
    "df = df.sort_values(['Match ID', 'PUUID'])\n",
    "\n",
    "# Assign a player number (1-10) within each match for team separation\n",
    "df['Player_Number'] = df.groupby('Match ID').cumcount() + 1  \n",
    "\n",
    "\n",
    "# Filter the dataset to only include rows for the target player\n",
    "player_df = df[df['PUUID'] == target_puuid].copy()\n",
    "\n",
    "def get_other_champions_conditional(row, full_df):\n",
    "\n",
    "    match_id = row['Match ID']\n",
    "    player_num = row['Player_Number']\n",
    "\n",
    "    # Team 1 consists of players 1-5, Team 2 consists of players 6-10\n",
    "    if player_num <= 5:\n",
    "        # Player is on Team 1, so opposing champions are from Team 2 (players 6-10)\n",
    "        other_champs = full_df[(full_df['Match ID'] == match_id) & \n",
    "                               (full_df['Player_Number'] > 5)]['Champion Name'].unique()\n",
    "    else:\n",
    "        # Player is on Team 2, so opposing champions are from Team 1 (players 1-5)\n",
    "        other_champs = full_df[(full_df['Match ID'] == match_id) & \n",
    "                               (full_df['Player_Number'] <= 5)]['Champion Name'].unique()\n",
    "\n",
    "    return list(other_champs)\n",
    "\n",
    "# Apply the function to each row for the target player to get the opposing champions list\n",
    "player_df['Other Champions List'] = player_df.apply(lambda row: get_other_champions_conditional(row, df), axis=1)\n",
    "\n",
    "# Explode the list of opposing champions to have one champion per row for easier analysis\n",
    "result = player_df.explode('Other Champions List')\n",
    "\n",
    "# Select relevant columns and rename for clarity\n",
    "result = result[['Match ID', 'PUUID', 'Champion Name', 'Other Champions List', 'Win']]\\\n",
    "         .rename(columns={'Other Champions List': 'Other Champion'})\n",
    "\n",
    "print(result)\n",
    "\n",
    "# Define output file path dynamically based on date range (assumes unix_dates_df is defined)\n",
    "file_path = (\n",
    "    r\"heatmap_\" +\n",
    "    str(unix_dates_df['Unix Start'].min()) + \"_\" +\n",
    "    str(unix_dates_df['Unix End'].max()) + \".xlsx\"\n",
    ")\n",
    "\n",
    "# Export the processed data to Excel for use in dashboard visualizations\n",
    "result.to_excel(file_path, index=False)\n",
    "\n",
    "print(\"Heatmap data successfully saved\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
